{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from skimage.transform import resize\n",
    "import h5py\n",
    "import glob\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import joblib\n",
    "\n",
    "class LoadAndNormalizeImages(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.scaler = MinMaxScaler()\n",
    "\n",
    "    def load_and_process_image(self, file_path):\n",
    "        image = nib.load(file_path).get_fdata()\n",
    "        image = self.scaler.fit_transform(image.reshape(-1, image.shape[-1])).reshape(image.shape)\n",
    "        return image\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        t1_path, t2_path, t1ce_path, flair_path = X\n",
    "        t1 = self.load_and_process_image(t1_path)\n",
    "        t2 = self.load_and_process_image(t2_path)\n",
    "        t1ce = self.load_and_process_image(t1ce_path)\n",
    "        flair = self.load_and_process_image(flair_path)\n",
    "        return np.stack([t1, t1ce, t2, flair], axis=3)\n",
    "\n",
    "class ResizeImages(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, target_shape=(128, 128, 128)):\n",
    "        self.target_shape = target_shape\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return resize(X, self.target_shape, mode='constant', anti_aliasing=True)\n",
    "\n",
    "class ResizeMasks(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, target_shape=(128, 128, 128)):\n",
    "        self.target_shape = target_shape\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        mask = resize(X, self.target_shape, mode='constant', anti_aliasing=False, preserve_range=True).astype(np.uint8)\n",
    "        return to_categorical(mask, num_classes=4)\n",
    "\n",
    "def save_patient_data(images, mask, output_path, patient_id):\n",
    "    output_file = os.path.join(output_path, f'patient_{patient_id}.h5')\n",
    "    with h5py.File(output_file, 'w') as hf:\n",
    "        hf.create_dataset('images', data=images, compression='gzip')\n",
    "        hf.create_dataset('masks', data=mask, compression='gzip')\n",
    "    print(f\"Imagenes y mascaras guardadas con numero de paciente {patient_id} como HDF5\")\n",
    "\n",
    "def create_pipeline(target_shape):\n",
    "    return Pipeline([\n",
    "        ('load_and_normalize_images', LoadAndNormalizeImages()),\n",
    "        ('resize_images', ResizeImages(target_shape=target_shape)),\n",
    "    ])\n",
    "\n",
    "def process_data_folder(data_folder, pipeline, output_path):\n",
    "    t1_list = sorted(glob.glob(os.path.join(data_folder, '*/*t1n.nii.gz')))\n",
    "    t2_list = sorted(glob.glob(os.path.join(data_folder, '*/*t2W.nii.gz')))\n",
    "    t1ce_list = sorted(glob.glob(os.path.join(data_folder, '*/*t1c.nii.gz')))\n",
    "    flair_list = sorted(glob.glob(os.path.join(data_folder, '*/*t2f.nii.gz')))\n",
    "    mask_list = sorted(glob.glob(os.path.join(data_folder, '*/*seg.nii.gz')))\n",
    "\n",
    "    for img in range(len(t1ce_list)):\n",
    "        print(f\"Now preparing image and masks number: {img}\")\n",
    "        image_paths = (t1_list[img], t2_list[img], t1ce_list[img], flair_list[img])\n",
    "        images = pipeline.transform(image_paths)\n",
    "        mask = nib.load(mask_list[img]).get_fdata().astype(np.uint8)\n",
    "        mask_resized = ResizeMasks(target_shape=pipeline.named_steps['resize_images'].target_shape).transform(mask)\n",
    "        save_patient_data(images, mask_resized, output_path, img)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    data_folder = 'GLIOMA'\n",
    "    target_shape = (128, 128, 128)\n",
    "    output_path = 'C:/Users/lcres/Desktop/modelo'\n",
    "\n",
    "    if not os.path.exists(output_path):\n",
    "        os.makedirs(output_path)\n",
    "\n",
    "    pipeline = create_pipeline(target_shape)\n",
    "    \n",
    "    # Guardar el pipeline\n",
    "    joblib.dump(pipeline, 'image_processing_pipeline.pkl')\n",
    "    \n",
    "    # Cargar y usar el pipeline para procesar una nueva carpeta\n",
    "    pipeline = joblib.load('image_processing_pipeline.pkl')\n",
    "    process_data_folder(data_folder, pipeline, output_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
